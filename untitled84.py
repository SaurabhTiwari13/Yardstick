# -*- coding: utf-8 -*-
"""Untitled84.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_T-1paascMWu7X5F8BuGY6z1nu_yuPSg
"""

pip install openai

pip install pinecone

pip install pinecone-client

pip install pinecone

import openai
from pinecone import Pinecone
import json

# Set your OpenAI and Pinecone API keys
from pinecone import Pinecone

# Set your OpenAI and Pinecone API keys
openai_api_key = 'YOUR_OPENAI_API_KEY'
pinecone_api_key = 'YOUR_PINECONE_API_KEY'

# Initialize Pinecone client
pinecone = Pinecone(api_key=pinecone_api_key, environment='production')  # Set environment accordingly

# Rest of the code remains unchanged
# ...


# Define a function to index documents into Pinecone DB
def index_documents(docs):
    # Assuming 'docs' is a list of dictionaries with 'id' and 'text' keys
    index_data = [{'id': str(doc['id']), 'vector': openai.Embed(doc['text'])} for doc in docs]
    pinecone.create_index(index_name='qa_index', dimension=768, metric='cosine', shards=1)
    pinecone.upsert_items(index_name='qa_index', items=index_data)

# Define a function to retrieve relevant documents from Pinecone DB
def retrieve_documents(query, num_results=5):
    query_vector = openai.Embed(query)
    results = pinecone.query(index_name='qa_index', query_vector=query_vector, top_k=num_results)
    return results

# Define a function to generate a response using OpenAI API
def generate_response(prompt):
    response = openai.Completion.create(
        model="text-davinci-003",  # You may use a different model
        prompt=prompt,
        max_tokens=150,
        temperature=0.7
    )
    return response.choices[0].text.strip()

# Define the main function for the QA bot
def qa_bot(question):
    # Step 1: Retrieve relevant documents
    retrieved_docs = retrieve_documents(question)

    # Step 2: Prepare a prompt for OpenAI GPT-3
    prompt = f"Question: {question}\nContext: "
    for doc in retrieved_docs:
        prompt += f"{doc['document']}\n"

    # Step 3: Generate a response using OpenAI GPT-3
    answer = generate_response(prompt)

    return answer

# Example usage
if __name__ == "__main__":
    # Example documents to index into Pinecone DB
    documents_to_index = [
        {'id': 1, 'text': 'Document 1 text...'},
        {'id': 2, 'text': 'Document 2 text...'},
        # Add more documents as needed
    ]

    # Index documents into Pinecone DB
    index_documents(documents_to_index)

    # Example question for the QA bot
    user_question = "What is the capital of France?"

    # Get the answer from the QA bot
    answer = qa_bot(user_question)

    # Display the answer
    print(f"Answer: {answer}")